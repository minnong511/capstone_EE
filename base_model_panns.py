import torch
import torch.nn as nn
import torch.optim as optim 
import torchaudio
import platform
import os 

from models import Cnn10  # models.pyì—ì„œ ì •ì˜ë¨
from torch.utils.data import Dataset

#-------------------------------------------------------------------------# 

def get_device():
    system = platform.system()

    if system == 'Darwin':  # macOS
        if torch.backends.mps.is_available():
            print("macOS + MPS ì‚¬ìš©")
            return torch.device('mps')
        else:
            print("macOSì§€ë§Œ MPS ì‚¬ìš© ë¶ˆê°€ â†’ CPUë¡œ ëŒ€ì²´")
            return torch.device('cpu')

    elif torch.cuda.is_available():  # Windows/Linux with GPU
        print("CUDA GPU ì‚¬ìš©")
        return torch.device('cuda')

    else:
        print("GPU ì‚¬ìš© ë¶ˆê°€ â†’ CPU ì‚¬ìš©")
        return torch.device('cpu')
# -------------------------------- 4ì›” 13ì¼ -------------------------------- # 

# ëª¨ë¸ ì°¾ìŒ : PANN // 

class PANNsCNN10(nn.Module):
    def __init__(self, checkpoint_path='./Model/pretrained/Cnn10.pth'):
        super().__init__()
        self.model = Cnn10(sample_rate=32000, window_size=1024, hop_size=320,
                           mel_bins=64, fmin=50, fmax=14000, classes_num=527)
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        self.model.load_state_dict(checkpoint['model'])
        self.model.eval()  # freeze

    def forward(self, x):
        with torch.no_grad():
            output = self.model(x)
            return output['embedding']  # (batch, 1024)

# ì»¤ìŠ¤í…€ ë¶„ë¥˜ê¸° (ì „ì´í•™ìŠµìš©)
class TransferClassifier(nn.Module):
    def __init__(self, input_dim=1024, num_classes=3): # ë‚´ê°€ ì¶œë ¥í•˜ê³  ì‹¶ì€ í´ë˜ìŠ¤ëŠ” ì—¬ê¸°ì„œ ìˆ˜ì •í•˜ë©´ ëœë‹¤
        super().__init__()
        self.classifier = nn.Sequential(
            nn.Linear(input_dim, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.classifier(x)

# í…ŒìŠ¤íŠ¸ ì‹¤í–‰
# if __name__ == '__main__':
#     model = PANNsCNN10('./Model/pretrained/Cnn10.pth')

#     # (batch_size, waveform_length) â†’ float32 ì¤‘ìš”!
#     dummy_input = torch.randn(2, 32000).float()

#     # PANNs ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ (B, 1, T)ë¡œ reshape í•˜ê¸° ë•Œë¬¸ì— 
#     # unsqueeze() ì“°ì§€ ë§ê³  ë°”ë¡œ float32 2ì°¨ì› í…ì„œë¥¼ ë„˜ê²¨ì•¼ í•¨.

#     emb = model(dummy_input)
#     print("ì„ë² ë”© shape:", emb.shape)

# -------------------------------- 4ì›” 14ì¼ -------------------------------- # 
# ì—¬ëŸ¬ ê°œë¥¼ ì „ì²˜ë¦¬í•˜ê³  ì‹¶ìœ¼ë‹ˆ ê·¸ì— ë§ê²Œ í´ë˜ìŠ¤ë¥¼ êµ¬í˜„í•˜ë©´ ëœë‹¤. 

# 1. .wav íŒŒì¼ ì—¬ëŸ¬ê°œ ë¡œë“œ (torchaudio ë˜ëŠ” librosa)

# 2. 32Khz ë¦¬ìƒ˜í”Œë§ + ëª¨ë…¸ ë³€í™˜ 

# 3. ëª¨ë¸ì— ë„£ê¸° ìœ„í•œ Waveform -> embedding ì¶”ì¶œ 

# 4. (embedding, label) ìŒì„ ëª¨ì•„ì„œ í•™ìŠµ 

class AudioEmbeddingDataset(Dataset): 
    def __init__(self, root_dir, model, sample_rate = 32000): 
        self.samples = [] 
        self.model = model 
        self.model.eval() 
        self.resampler = torchaudio.transforms.Resample(orig_freq=44100, new_freq=sample_rate)  # default wav: 44.1kHz
        self.label_dict = {}

        for idx, label_name in enumerate(sorted(os.listdir(root_dir))): 
            self.label_dict[label_name] = idx 
            label_dir = os.path.join(root_dir,label_name)
            for frame in os.listdir(label_dir): 
                if frame.endswith(".wav"): 
                    fpath = os.path.join(label_dir, name)
                    self.samples.append((fpath,idx)) 
    
    def __len__(self):
        return len(self.samples) 
    
    def __getitem__(self,idx): 
        fpath, label = self.samples[idx] 
        waveform, sr = torchaudio.load(fpath) 

        # ëª¨ë…¸ ë³€í™˜ 
        if waveform.shape[0] > 1 : 
            waveform = waveform.mean(dim = 0 , keepdim= True) 
        
        # ë¦¬ìƒ˜í”Œë§ -> 32000ìœ¼ë¡œ ë§Œë“¤ì–´ì¤˜ì•¼ í•œë‹¤. 
        if sr != 32000:
            waveform = self.resampler(dim = 0, keepdim = True) 
        
        waveform = waveform.squeeze(0).unsqueeze(0)  # â†’ (1, length)

        # ëª¨ë¸ì— ë„£ì–´ì„œ ì„ë² ë”©ë§Œ ì¶”ì¶œí•˜ë˜, í•™ìŠµì„ í•˜ì§€ ì•Šê¸° ìœ„í•´ no_gradë¥¼ ì‚¬ìš©í•œë‹¤. 
        with torch.no_grad():
            emb = self.model(waveform)[0]  # â†’ (512,) or (1024,) depending on model

        return emb, label

# ë°ì´í„°ì…‹ ìë™ ì²˜ë¦¬ ëª¨ë¸ 

# embedding  -> classifer -> label 
# ì¼ë‹¨ì€ ìµœëŒ€í•œ ê°„ë‹¨í•˜ê²Œ ëª¨ë¸ êµ¬ì„± 
# í•™ìŠµ ë£¨í”„ êµ¬ì„± 
# í´ë˜ìŠ¤ëŠ” ëª‡ ê°œë¡œ ë¶„ë¥˜?? 

class TransferClassifier(nn.Module):
    # input_dimì€ CNN10 = 1024, CNN6 = 512 
    def __init__(self,input_dim = 1024,num_classes =3): 
        super().__init__() 
        self.classifier = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(256,128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128,num_classes)
        )
    
    def forward(self,x): 
        return self.classifier(x) 


# ----------- ì „ì´í•™ìŠµ í›„ì— ì„ë² ë”© ì¶”ì¶œí•˜ê³ , ì¶”ì¶œëœ ì„ë² ë”©ê³¼ ë¼ë²¨ë¡œ Classifierë¥¼ êµ¬í˜„í•˜ëŠ” ë¶€ë¶„ì„
def train_classifier(classifier, dataloader, num_classes, epochs=10):
    device = get_device() # ë§¥ì—ì„œëŠ” ì¿ ë‹¤ ì•ˆë˜ë‹ˆ ìœˆë„ìš° ì»´ì—ì„œ êµ¬í˜„ ã„±ã„± 
    classifier = classifier.to(device) 
    optimizer = optim.Adam(classifier.parameters(), lr = 1e-3)
    criterion = nn.CrossEntropyLoss() 

    for epoch in range(epoch): 
        classifier.train()
        total_loss = 0 
        correct = 0 
        total = 0 

        for x,y in dataloader: 
            x, y = x.to(device), y.to(device)

            optimizer.zero_grad()
            logits = classifier(x) 
            loss = criterion(logits,y) 
            loss.backward() 
            optimizer.step()

            total_loss += loss.item() 
            pred = torch.argmax(logits, dim = 1) 
            correct += (pred == y).sum().item()
            total += y.size(0)

        acc = correct / total 
        print(f"[{epoch+1}/{epochs}] Loss: {total_loss:.4f}, Accuracy: {acc:.4f}")


#------------------------ 4ì›” 15ì¼ ê°œë°œ ---------------------# 
# --- ì˜¤ë””ì˜¤ ì¶”ë¡  ëª¨ë¸ ê°œë°œ --- #  

def infer_audio(file_path, room_id, panns_model, classifier_model, label_dict, device = "cpu"):
    import torchaudio
    import torch 

    # 1. ì˜¤ë””ì˜¤ ë¡œë“œ 
    waveform, sr = torchaudio.load(file_path)
    if waveform.shape[0] > 1:  
        waveform = waveform.mean(dim = 0, keepdim= True)
    
    # 2. ë¦¬ìƒ˜í”Œë§
    if sr != 32000:
        resampler = torchaudio.transforms.Resample(orig_freq=sr, new_freq = 32000)
        waveform = resampler(waveform)

    waveform = waveform.squeeze(0).unsqueeze(0).to(device)
    
    # 3. ì„ë² ë”© ì¶”ì¶œ
    with torch.no_grad():
        embedding = panns_model(waveform) 

    # 4. ë¶„ë¥˜ê¸° ì¶”ì¶œ 
    with torch.no_grad():
        logits = classifier_model(embedding.to(device))
        pred_idx = torch.argmax(logits, dim = 1).item()

    # 5. ì¶œë ¥ 
    idx_to_label = {v: k for k, v in label_dict.items()}
    pred_label = idx_to_label[pred_idx]

    print(f"ğŸ§  Predicted: {pred_label} | ğŸ“ Room {room_id}")
    return {"room_id": room_id, "predicted_class": pred_label}